# GIST
<div id="top"></div>


<!-- PROJECT LOGO -->
<br />
<div align="center">
  <h3 align="center">GIST</h3>

  <p align="center">
     We introduce GIST, a deep learning-enabled Gene expression and histology Integration for Spatial cellular Profiling. GIST leverages histopathology foundation models pre-trained on millions of histology images to enhance feature extraction and employs a hybrid graph transformer model to integrate image and transcriptome features. Validated on human lung, breast, and colorectal cancers datasets, GIST effectively reveals spatial domains and significantly improves the accuracy of segmenting the microenvironment and de-noising transcriptomics data.
    <br />
    <a href="https://github.com/lengjk1214/GIST"><strong>Explore the docs(arxiv) »</strong></a>
    <br />
    <br />
  </p>
</div>



<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#Structure">Structure of the GIST</a>
    </li>
    <li><a href="#Requirements">Requirements</a></li>
    <li>
      <a href="#Dataset-Setting">Dataset Setting</a>
      <ul>
        <li><a href="#Data-availabel">Data available</a></li>
        <li><a href="#Folder-Structure">Folder Structure</a></li>
      </ul>
    </li>
    <li><a href="#Train">Train</a>
        <ul>
        <li><a href="#Nanostring">Nanostring</a></li>
        <li><a href="#breast">Breast</a></li>
        <li><a href="#colorectal ">colorectal </a></li>
      </ul>
    </li>
    <li><a href="#cite">Cite</a></li>
  </ol>
</details>



## Structure of the GIST

[![method][product-screenshot]](https://github.com/lengjk1214/GIST)

GIST contains 1. Extracting features from gene expression and image patches for data construction. For the cell populations of the four different anatomic sites, next-generation sequencing was used to detect the types, amounts and spatial location of various types of gene produced by specific cell types. The overall inputs to GIST include gene expression profiles and cell location formation obtained by sequencing as well as multiplex immunofluorescence images. 2. Utilizing hybrid graph transformer model for feature extraction and fusion from transcriptomic and image data. The image patch is fed into the feature extractor to get embedding feature $x_i$. For any cell $v_i$, it includes gene expression information, gene neighbourhood graph and image information. These information are merged and fed into three different graph transformer autoencoders to get the final gene embedding loss, image embedding loss and hybrid embedding loss respectively. 3. Applying downstream approaches for the identification of spatial domains and the denoising of gene expression data.

* In the data preprocessing stage, we obtained gene expression profiles and cell spatial location information from spatial transcriptomic data, and selected multiplex immunofluorescence images containing cell morphology as multimodal input to GIST.
* In feature extractor and hybrid graph transformer model stage, we employed the pre-trained self-supervised learning-enhanced image feature extraction as the feature extractor for multiplex immunofluorescence images. First, the initial image was divided into patches according to the spatial position of the cells. These segmented image patches were used as the input of the image feature extraction, and then pre-trained model employed self-supervised learning to extract image features, leveraging this approach to enhance the discriminative power of the learned representations. The extracted image features obtained and the transcriptome features obtained by gene expression profiles were then input into hybrid graph transformer model to obtain the final enhanced gene expression profile.
* In downstream analysis stage, we analyzed the transcriptomic alterations within the enhanced datasets generated by GIST, facilitating various forms of downstream analysis.

<p align="right">(<a href="#top">back to top</a>)</p>



## Requirements

Required modules can be installed via requirements.txt under the project root
```
pip install -r requirements.txt
```

```
anndata==0.8.0
conda==23.1.0
h5py==3.8.0
louvain==0.8.2
matplotlib==3.5.3
opencv-python==4.8.1.78
pandas==1.3.4
Pillow==9.5.0
rpy2==2.9.4
scanpy==1.9.1
scipy==1.7.3
seaborn==0.12.2
stlearn==0.4.12
tensorboard==2.11.2
tensorflow==2.11.0
tifffile==2021.11.2
torch==1.13.1
torch-geometric==2.3.1
torchaudio==0.13.1
torchvision==0.14.1
umap-learn==0.5.4
```

<p align="right">(<a href="#top">back to top</a>)</p>



<!-- GETTING STARTED -->
## Dataset Setting



### Data available

1. NanoString CosMx SMI [here](https://nanostring.com/products/cosmx-spatial-molecular-imager/ffpe-dataset/nsclc-ffpe-dataset/)
2. Human breast cancer [here](https://www.10xgenomics.com/datasets/human-breast-cancer-block-a-section-1-1-standard-1-0-0)
3. Human breast cancer2 [here](https://www.10xgenomics.com/datasets/human-breast-cancer-block-a-section-1-1-standard-1-0-0)
4. Human Colorectal Cancer [here](https://www.10xgenomics.com/datasets/human-colorectal-cancer-11-mm-capture-area-ffpe-2-standard)

### Folder Structure
```
├── requirement.txt
├── dataset
│   └── nanostring
│        └── Lung13_exprMat_file.csv
│        └── matched_annotation_all.csv
│        └── fov1
│              ├── CellComposite_F001.jpg
│              ├── sampledata.h5ad
│        └── fov2
│              ├── CellComposite_F002.jpg
│              ├── sampledata.h5ad
│   └── human cancer
│        └── full_image.tif
│        └── sampledata.h5ad
│   └── colorectal
│        └── full_image.tif
│        └── sampledata.h5ad
|
├── checkpoint
│   └── nanostring_final
│        ├── final.pth
│   └── human cancer
│        ├── final.pth
│   └── colorectal
│        ├── final.pth
```


## Train
1. for NanoString CosMx SMI 
```
python3 train.py --dataset nanostring --test_only 0 --save_path ../checkpoint/nanostring/ --seed 1234 --epochs 1000 --lr 1e-3 
```
2. for Human Breast Cancer
```
python3 train.py --dataset breast --test_only 0 --save_path ../checkpoint/reast/ --seed 1234 --epochs 1000 --lr 1e-3 
```
3. for Human Breast Cancer2 
```
python3 train.py --dataset breast2 --test_only 0 --save_path ../checkpoint/breast2/ --seed 1234 --epochs 1000 --lr 1e-3 
```
4. for Human Colorectal Cancer
```
python3 train.py --dataset colorectal --test_only 0 --save_path ../checkpoint/colorectal/ --seed 1234 --epochs 1000 --lr 1e-3 
```
<p align="right">(<a href="#top">back to top</a>)</p>




## Cite

Please cite our paper if you use this code in your own work:

```

```

<p align="right">(<a href="#top">back to top</a>)</p>
